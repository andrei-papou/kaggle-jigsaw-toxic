{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import typing_extensions as t_ext\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers.models.auto.modeling_auto import AutoModelForSequenceClassification\n",
    "from transformers.models.auto.tokenization_auto import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path('/home/jovyan/jigsaw-toxic/data/datasets/ccc-2017-multilabel')\n",
    "COMBINED_DIR = Path('/home/jovyan/jigsaw-toxic/data/datasets/combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la $DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv(DATASET_DIR / 'train_no_leak.csv')\n",
    "all_with_leak_df = pd.read_csv(COMBINED_DIR / 'train_comment_classification_challenge_2017.csv')\n",
    "valid_df = pd.read_csv(COMBINED_DIR / 'valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['n_flags'] = all_df.progress_apply(lambda row: row['toxic'] + row['severe_toxic'] + row['obscene'] + row['threat'] + row['insult'] + row['identity_hate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[all_df['n_flags'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(DATASET_DIR / 'train_no_leak_expanded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TokenizedText(t_ext.TypedDict):\n",
    "    input_ids: torch.Tensor\n",
    "    attention_mask: torch.Tensor\n",
    "\n",
    "\n",
    "def _preprocess_tokenizer_output(output: t.Dict[str, t.Any]) -> _TokenizedText:\n",
    "    return {\n",
    "        'input_ids': torch.tensor(output['input_ids']),\n",
    "        'attention_mask': torch.tensor(output['attention_mask']),\n",
    "    }\n",
    "\n",
    "\n",
    "class ValidDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer, max_len: int) -> None:\n",
    "        super().__init__()\n",
    "        self._df = df\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> t.Tuple[int, _TokenizedText, _TokenizedText]:\n",
    "        record = self._df.iloc[idx]\n",
    "        text_more = str(record['more_toxic'])\n",
    "        text_less = str(record['less_toxic'])\n",
    "\n",
    "        tokenized_more = _preprocess_tokenizer_output(self._tokenizer(\n",
    "            text_more,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self._max_len,\n",
    "            return_attention_mask=True))  # type: ignore\n",
    "        tokenized_less = _preprocess_tokenizer_output(self._tokenizer(\n",
    "            text_less,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self._max_len,\n",
    "            return_attention_mask=True))  # type: ignore\n",
    "\n",
    "        return idx, tokenized_more, tokenized_less\n",
    "\n",
    "\n",
    "class PredictDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer, max_len: int) -> None:\n",
    "        super().__init__()\n",
    "        self._df = df\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> t.Tuple[int, _TokenizedText]:\n",
    "        record = self._df.iloc[idx]\n",
    "        text = str(record['comment_text'])\n",
    "\n",
    "        tokenized_text = _preprocess_tokenizer_output(self._tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self._max_len,\n",
    "            return_attention_mask=True))  # type: ignore\n",
    "\n",
    "        return idx, tokenized_text\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_valid_toxicity_labels_by_model(\n",
    "        valid_df: pd.DataFrame,\n",
    "        model_checkpoint: str = 'unitary/toxic-bert',\n",
    "        batch_size: int = 8,\n",
    "        num_workers: int = 8,\n",
    "        device: str = 'cuda',\n",
    "        threshold: float = 0.5,\n",
    "        not_availabel_tag: str = '<na>') -> t.Tuple[t.List[int], t.List[str], t.List[str]]:\n",
    "    valid_df = valid_df.copy()\n",
    "    valid_df['more_toxic_bitmap_label'] = not_availabel_tag\n",
    "    valid_df['less_toxic_bitmap_label'] = not_availabel_tag\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint).to(device)\n",
    "    dataset = ValidDataset(\n",
    "        valid_df,\n",
    "        tokenizer=AutoTokenizer.from_pretrained(model_checkpoint),\n",
    "        max_len=256)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    idx_list, more_toxic_bitmap_label_list, less_toxic_bitmap_label_list = [], [], []\n",
    "    for idx, tokenized_more, tokenized_less in tqdm(data_loader):\n",
    "        preds_more = model(tokenized_more['input_ids'].to(device), tokenized_more['attention_mask'].to(device))[0]\n",
    "        preds_less = model(tokenized_less['input_ids'].to(device), tokenized_less['attention_mask'].to(device))[0]\n",
    "        labels_more, labels_less = (preds_more > threshold).int(), (preds_less > threshold).int()\n",
    "        for i, lm, ll in zip(idx, labels_more, labels_less):\n",
    "            idx_list.append(i)\n",
    "            more_toxic_bitmap_label_list.append(' '.join([str(x) for x in lm.flatten().tolist()]))\n",
    "            less_toxic_bitmap_label_list.append(' '.join([str(x) for x in ll.flatten().tolist()]))\n",
    "    return idx_list, more_toxic_bitmap_label_list, less_toxic_bitmap_label_list\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_eval_toxicity_labels_by_model(\n",
    "        eval_df: pd.DataFrame,\n",
    "        cls_list: t.List[str],\n",
    "        model_checkpoint: str = 'unitary/toxic-bert',\n",
    "        batch_size: int = 8,\n",
    "        num_workers: int = 8,\n",
    "        device: str = 'cuda',\n",
    "        threshold: float = 0.5,\n",
    "        not_availabel_tag: str = '<na>') -> t.Tuple[t.List[int], t.List[str], t.List[str]]:\n",
    "    eval_df = eval_df.copy()\n",
    "    for cls in cls_list:\n",
    "        eval_df[f'{cls}_score'] = float('nan')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint).to(device)\n",
    "    dataset = ValidDataset(\n",
    "        valid_df,\n",
    "        tokenizer=AutoTokenizer.from_pretrained(model_checkpoint),\n",
    "        max_len=256)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    idx_list, more_toxic_bitmap_label_list = [], []\n",
    "    for idx, tokenized_more, tokenized_less in tqdm(data_loader):\n",
    "        preds_more = model(tokenized_more['input_ids'].to(device), tokenized_more['attention_mask'].to(device))[0]\n",
    "        preds_less = model(tokenized_less['input_ids'].to(device), tokenized_less['attention_mask'].to(device))[0]\n",
    "        labels_more, labels_less = (preds_more > threshold).int(), (preds_less > threshold).int()\n",
    "        for i, lm, ll in zip(idx, labels_more, labels_less):\n",
    "            idx_list.append(i)\n",
    "            more_toxic_bitmap_label_list.append(' '.join([str(x) for x in lm.flatten().tolist()]))\n",
    "            less_toxic_bitmap_label_list.append(' '.join([str(x) for x in ll.flatten().tolist()]))\n",
    "    return idx_list, more_toxic_bitmap_label_list, less_toxic_bitmap_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list, more_toxic_bitmap_label_list, less_toxic_bitmap_label_list = get_toxicity_labels_by_model(valid_df, model_checkpoint='unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labeled_df = valid_df.copy()\n",
    "valid_labeled_df.loc[idx_list, 'more_toxic_bitmap_label'] = more_toxic_bitmap_label_list\n",
    "valid_labeled_df.loc[idx_list, 'less_toxic_bitmap_label'] = less_toxic_bitmap_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labeled_df.to_csv(DATASET_DIR / 'valid_labeled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labeled_df = pd.read_csv(DATASET_DIR / 'valid_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubtc_idx_list, ubtc_more_toxic_bitmap_label_list, ubtc_less_toxic_bitmap_label_list = get_toxicity_labels_by_model(valid_df, model_checkpoint='unitary/unbiased-toxic-roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>certainty</th>\n",
       "      <th>more_toxic_bitmap_label</th>\n",
       "      <th>less_toxic_bitmap_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I think people say its not so absurd, because ...</td>\n",
       "      <td>Re Vandalism. . . .  that is because the user ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must have the lowest IQ of anyone on wikip...</td>\n",
       "      <td>Wha's a reliable source mike? Something that c...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1 0 1 0 1 0</td>\n",
       "      <td>1 0 0 0 1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks for removing more of his anonymous, un...</td>\n",
       "      <td>To Bad\\nyou dont have the balls to sign in, I ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1 0 0 0 1 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\n\\nActually, it clearly does not involve pow...</td>\n",
       "      <td>, 18 November 2006 (UTC)\\n\\nWell comrade. Look...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are not cool \\n\\nYou are the most hated f...</td>\n",
       "      <td>\"== Hey Fuck-head==\\nHey, just wanted to say \"...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1 0 1 0 1 0</td>\n",
       "      <td>1 0 1 0 1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10103</th>\n",
       "      <td>Heeeeeeeeeeeeeeyyyyyyyyyyyy dude! Sup!</td>\n",
       "      <td>you deleted my page \\nand i am extrememly mad ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>ATTENTION:''''''\\n\\nANYONE WHO OPPOSES MY OPIN...</td>\n",
       "      <td>suck dick u disrespectful swearing wank!!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1 0 1 0 1 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>Oh yah, and Bayerischermann is another guy try...</td>\n",
       "      <td>Thanks. Also thanks for freezing the article. ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10106</th>\n",
       "      <td>I had to chop out a section specifically compa...</td>\n",
       "      <td>\"\\n\\nHorrifyingly enough, \"\"ritualistic penis ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>Please kill yourself.</td>\n",
       "      <td>That's a load of crap. You are letting trolls ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1 0 1 0 0 0</td>\n",
       "      <td>1 0 0 1 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10108 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              less_toxic  \\\n",
       "0      I think people say its not so absurd, because ...   \n",
       "1      You must have the lowest IQ of anyone on wikip...   \n",
       "2       Thanks for removing more of his anonymous, un...   \n",
       "3      \"\\n\\nActually, it clearly does not involve pow...   \n",
       "4       You are not cool \\n\\nYou are the most hated f...   \n",
       "...                                                  ...   \n",
       "10103          Heeeeeeeeeeeeeeyyyyyyyyyyyy dude! Sup!      \n",
       "10104  ATTENTION:''''''\\n\\nANYONE WHO OPPOSES MY OPIN...   \n",
       "10105  Oh yah, and Bayerischermann is another guy try...   \n",
       "10106  I had to chop out a section specifically compa...   \n",
       "10107                            Please kill yourself.     \n",
       "\n",
       "                                              more_toxic  certainty  \\\n",
       "0      Re Vandalism. . . .  that is because the user ...   0.666667   \n",
       "1      Wha's a reliable source mike? Something that c...   1.000000   \n",
       "2      To Bad\\nyou dont have the balls to sign in, I ...   1.000000   \n",
       "3      , 18 November 2006 (UTC)\\n\\nWell comrade. Look...   0.666667   \n",
       "4      \"== Hey Fuck-head==\\nHey, just wanted to say \"...   1.000000   \n",
       "...                                                  ...        ...   \n",
       "10103  you deleted my page \\nand i am extrememly mad ...   1.000000   \n",
       "10104          suck dick u disrespectful swearing wank!!   1.000000   \n",
       "10105  Thanks. Also thanks for freezing the article. ...   1.000000   \n",
       "10106  \"\\n\\nHorrifyingly enough, \"\"ritualistic penis ...   0.666667   \n",
       "10107  That's a load of crap. You are letting trolls ...   0.666667   \n",
       "\n",
       "      more_toxic_bitmap_label less_toxic_bitmap_label  \n",
       "0                 1 0 0 0 0 0             0 0 0 0 0 0  \n",
       "1                 1 0 1 0 1 0             1 0 0 0 1 0  \n",
       "2                 1 0 0 0 1 0             0 0 0 0 0 0  \n",
       "3                 1 0 0 0 0 0             0 0 0 0 0 0  \n",
       "4                 1 0 1 0 1 0             1 0 1 0 1 0  \n",
       "...                       ...                     ...  \n",
       "10103             0 0 0 0 0 0             0 0 0 0 0 0  \n",
       "10104             1 0 1 0 1 0             0 0 0 0 0 0  \n",
       "10105             1 0 0 0 0 0             0 0 0 0 0 0  \n",
       "10106             1 0 0 0 0 0             0 0 0 0 0 0  \n",
       "10107             1 0 1 0 0 0             1 0 0 1 0 0  \n",
       "\n",
       "[10108 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36149584487534625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_labeled_df[valid_labeled_df['more_toxic_bitmap_label'] == valid_labeled_df['less_toxic_bitmap_label']]) / len(valid_labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCC2017_CLS_LIST = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "def _bitmap_to_readable(label: str) -> str:\n",
    "    return ' '.join([l for l, b in zip(CCC2017_CLS_LIST, label.split(' ')) if int(b) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toxic obscene insult'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bitmap_to_readable('1 0 1 0 1 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e3dabe768440658a758b938088b284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddb1937ca54fc5bb1cccc3e6e239c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_readable_label(row: t.Dict[str, int]) -> str:\n",
    "    return ' '.join([cls for cls in CCC2017_CLS_LIST if row[cls]])\n",
    "\n",
    "def build_bitmap_label(row: t.Dict[str, int]) -> str:\n",
    "    return ' '.join([str(row[cls]) for cls in CCC2017_CLS_LIST])\n",
    "\n",
    "\n",
    "all_df['bitmap_label'] = all_df.progress_apply(lambda row: build_bitmap_label(row), axis=1)\n",
    "all_df['readable_label'] = all_df.progress_apply(lambda row: build_readable_label(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_pairs_v8(all_df: pd.DataFrame, valid_df: pd.DataFrame, samples_per_pair: int = 5) -> pd.DataFrame:\n",
    "    row_list = []\n",
    "    for _, row in tqdm(valid_df.iterrows(), total=len(valid_df)):\n",
    "        more_row_population_df = all_df[all_df['bitmap_label'] == row['more_toxic_bitmap_label']]\n",
    "        less_row_population_df = all_df[all_df['bitmap_label'] == row['less_toxic_bitmap_label']]\n",
    "        more_row_df = more_row_population_df.sample(n=min(samples_per_pair, len(more_row_population_df)))\n",
    "        less_row_df = less_row_population_df.sample(n=min(samples_per_pair, len(less_row_population_df)))\n",
    "        for (_, more_row), (_, less_row) in zip(more_row_df.iterrows(), less_row_df.iterrows()):\n",
    "            row_list.append({\n",
    "                'more_toxic': str(more_row['comment_text']),\n",
    "                'less_toxic': str(less_row['comment_text']),\n",
    "                'more_toxic_bitmap_label': str(more_row['bitmap_label']),\n",
    "                'less_toxic_bitmap_label': str(less_row['bitmap_label']),\n",
    "            })\n",
    "    return pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f80fb38cab4a2c97f67aa50a76b787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pair_v8_df = mine_pairs_v8(all_df=all_df, valid_df=valid_labeled_df, samples_per_pair=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic_bitmap_label</th>\n",
       "      <th>less_toxic_bitmap_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate you \\n\\ni;uhbsirtubgyihihlkjngkjbnkgjnbkj...</td>\n",
       "      <td>Tuesday's With Morrie Movie Fact\\n\\nIn the Fil...</td>\n",
       "      <td>1 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dean Gaffney \\n\\nJPS, I'm not suprised it was ...</td>\n",
       "      <td>The situation is either every longer term edit...</td>\n",
       "      <td>1 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do research \\n\\nplease do some research before...</td>\n",
       "      <td>posthumous adoption \\n\\nUh, this means that he...</td>\n",
       "      <td>1 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop adding unsourced, biased info to Joseph B...</td>\n",
       "      <td>Also, according to Wikipedia:Blocking policy, ...</td>\n",
       "      <td>1 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leftcoastman \\n\\nSeriously, you're a whiny lit...</td>\n",
       "      <td>Wayward likes teeth in his crust!</td>\n",
       "      <td>1 0 0 0 0 0</td>\n",
       "      <td>0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50523</th>\n",
       "      <td>}}\\n\\n{{Unblock|Impudent, feckless, dick. How ...</td>\n",
       "      <td>or else I WOULD DESTROY YOU!!!!!</td>\n",
       "      <td>1 0 1 0 0 0</td>\n",
       "      <td>1 0 0 1 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50524</th>\n",
       "      <td>\"\\nYea. It is weird. ;) Man, that does suck. H...</td>\n",
       "      <td>I'm gonna beat you to a bloody pulp then shoot...</td>\n",
       "      <td>1 0 1 0 0 0</td>\n",
       "      <td>1 0 0 1 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50525</th>\n",
       "      <td>They're about to start construction on new lin...</td>\n",
       "      <td>I'ma smack ya upside da head wit a shovel \\n\\n...</td>\n",
       "      <td>1 0 1 0 0 0</td>\n",
       "      <td>1 0 0 1 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50526</th>\n",
       "      <td>\"\\n\\n Era's \\n\\nNot every single day of WWE hi...</td>\n",
       "      <td>you are part of isis \\n\\nCouple of days ago u ...</td>\n",
       "      <td>1 0 1 0 0 0</td>\n",
       "      <td>1 0 0 1 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50527</th>\n",
       "      <td>Again, not half-jokingly: how do I remove the ...</td>\n",
       "      <td>-good i hope you die inshallah</td>\n",
       "      <td>1 0 1 0 0 0</td>\n",
       "      <td>1 0 0 1 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50528 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              more_toxic  \\\n",
       "0      Hate you \\n\\ni;uhbsirtubgyihihlkjngkjbnkgjnbkj...   \n",
       "1      Dean Gaffney \\n\\nJPS, I'm not suprised it was ...   \n",
       "2      do research \\n\\nplease do some research before...   \n",
       "3      Stop adding unsourced, biased info to Joseph B...   \n",
       "4      Leftcoastman \\n\\nSeriously, you're a whiny lit...   \n",
       "...                                                  ...   \n",
       "50523  }}\\n\\n{{Unblock|Impudent, feckless, dick. How ...   \n",
       "50524  \"\\nYea. It is weird. ;) Man, that does suck. H...   \n",
       "50525  They're about to start construction on new lin...   \n",
       "50526  \"\\n\\n Era's \\n\\nNot every single day of WWE hi...   \n",
       "50527  Again, not half-jokingly: how do I remove the ...   \n",
       "\n",
       "                                              less_toxic  \\\n",
       "0      Tuesday's With Morrie Movie Fact\\n\\nIn the Fil...   \n",
       "1      The situation is either every longer term edit...   \n",
       "2      posthumous adoption \\n\\nUh, this means that he...   \n",
       "3      Also, according to Wikipedia:Blocking policy, ...   \n",
       "4                      Wayward likes teeth in his crust!   \n",
       "...                                                  ...   \n",
       "50523                   or else I WOULD DESTROY YOU!!!!!   \n",
       "50524  I'm gonna beat you to a bloody pulp then shoot...   \n",
       "50525  I'ma smack ya upside da head wit a shovel \\n\\n...   \n",
       "50526  you are part of isis \\n\\nCouple of days ago u ...   \n",
       "50527                     -good i hope you die inshallah   \n",
       "\n",
       "      more_toxic_bitmap_label less_toxic_bitmap_label  \n",
       "0                 1 0 0 0 0 0             0 0 0 0 0 0  \n",
       "1                 1 0 0 0 0 0             0 0 0 0 0 0  \n",
       "2                 1 0 0 0 0 0             0 0 0 0 0 0  \n",
       "3                 1 0 0 0 0 0             0 0 0 0 0 0  \n",
       "4                 1 0 0 0 0 0             0 0 0 0 0 0  \n",
       "...                       ...                     ...  \n",
       "50523             1 0 1 0 0 0             1 0 0 1 0 0  \n",
       "50524             1 0 1 0 0 0             1 0 0 1 0 0  \n",
       "50525             1 0 1 0 0 0             1 0 0 1 0 0  \n",
       "50526             1 0 1 0 0 0             1 0 0 1 0 0  \n",
       "50527             1 0 1 0 0 0             1 0 0 1 0 0  \n",
       "\n",
       "[50528 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pair_v8_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 28213472\n",
      "drwxr-xr-x  2 jovyan users        4096 Jan 27 16:07 .\n",
      "drwxr-xr-x 11 jovyan users        4096 Jan 26 19:03 ..\n",
      "-rw-r--r--  1 jovyan users        1699 Jan 12 11:46 label_toxicity.csv\n",
      "-rw-r--r--  1 jovyan users    64981283 Jan 13 08:38 train_no_leak.csv\n",
      "-rw-r--r--  1 jovyan users    67448851 Jan 13 08:40 train_no_leak_expanded.csv\n",
      "-rw-r--r--  1 jovyan users    30080933 Jan  6 20:31 train_no_leak_pair.csv\n",
      "-rw-r--r--  1 jovyan users    38018364 Dec 30 18:35 train_no_leak_pair_harder_1.csv\n",
      "-rw-r--r--  1 jovyan users    38087288 Dec 30 18:35 train_no_leak_pair_harder_2.csv\n",
      "-rw-r--r--  1 jovyan users    37854841 Dec 30 18:35 train_no_leak_pair_harder_3.csv\n",
      "-rw-r--r--  1 jovyan users    37854841 Dec 30 12:17 train_no_leak_pair_harder.csv\n",
      "-rw-r--r--  1 jovyan users  3418444331 Jan 12 12:03 train_no_leak_pair_v2.csv\n",
      "-rw-r--r--  1 jovyan users 24790812945 Jan 12 12:02 train_no_leak_pair_v2_full.csv\n",
      "-rw-r--r--  1 jovyan users    28057742 Jan 13 10:30 train_no_leak_pair_v3.csv\n",
      "-rw-r--r--  1 jovyan users    44014513 Jan 13 19:12 train_no_leak_pair_v4.csv\n",
      "-rw-r--r--  1 jovyan users   156676228 Jan 14 12:03 train_no_leak_pair_v5.csv\n",
      "-rw-r--r--  1 jovyan users    84257679 Jan 25 18:46 train_no_leak_pair_v6.csv\n",
      "-rw-r--r--  1 jovyan users    31978315 Jan 26 12:25 train_no_leak_pair_v7.csv\n",
      "-rw-r--r--  1 jovyan users     4447620 Jan 11 11:44 train_no_leak_toxic.csv\n",
      "-rw-r--r--  1 jovyan users     8876296 Jan 27 16:07 valid_labeled.csv\n",
      "-rw-r--r--  1 jovyan users     8633656 Jan 13 08:38 valid_pair.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -la $DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_v8_df.to_csv(DATASET_DIR / 'train_no_leak_pair_v8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L:\n",
    "    TOXIC = 'toxic'\n",
    "    SEVERE_TOXIC = 'severe_toxic'\n",
    "    INSULT = 'insult'\n",
    "    OBSCENE = 'obscene'\n",
    "    IDENTITY_HATE = 'identity_hate'\n",
    "    THREAT = 'threat'\n",
    "\n",
    "\n",
    "class MoreCondition:\n",
    "\n",
    "    def mask(self, less_label_set: t.Set[str], df: pd.DataFrame) -> t.Optional[pd.Series]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class SimpleMoreCondition(MoreCondition):\n",
    "    _ALL_LABEL_SET = {\n",
    "        L.TOXIC,\n",
    "        L.SEVERE_TOXIC,\n",
    "        L.INSULT,\n",
    "        L.OBSCENE,\n",
    "        L.IDENTITY_HATE,\n",
    "        L.THREAT,\n",
    "    }\n",
    "\n",
    "    def mask(self, less_label_set: t.Set[str], df: pd.DataFrame) -> t.Optional[pd.Series]:\n",
    "        \"\"\"\n",
    "        More row contains all the labels from the `less_label_set` and \n",
    "        at least one label from the `self._ALL_LABEL_SET - less_label_set`.\n",
    "        \"\"\"\n",
    "        all_less_labels_mask: t.Optional[pd.Series] = None\n",
    "        for label in less_label_set:\n",
    "            all_less_labels_mask = all_less_labels_mask & (df[label] == 1) \\\n",
    "                if all_less_labels_mask is not None else (df[label] == 1)\n",
    "        at_least_one_more_label_mask: t.Optional[pd.Series] = None\n",
    "        for label in self._ALL_LABEL_SET - less_label_set:\n",
    "            at_least_one_more_label_mask = at_least_one_more_label_mask | (df[label] == 1) \\\n",
    "                if at_least_one_more_label_mask is not None else (df[label] == 1)\n",
    "        if all_less_labels_mask is None and at_least_one_more_label_mask is None:\n",
    "            return None\n",
    "        elif all_less_labels_mask is not None and at_least_one_more_label_mask is None:\n",
    "            return all_less_labels_mask\n",
    "        elif all_less_labels_mask is None and at_least_one_more_label_mask is not None:\n",
    "            return at_least_one_more_label_mask\n",
    "        assert all_less_labels_mask is not None and at_least_one_more_label_mask is not None\n",
    "        return all_less_labels_mask & at_least_one_more_label_mask\n",
    "\n",
    "\n",
    "class ComparisonBasedMoreCondition(MoreCondition):\n",
    "\n",
    "    def __init__(self, less_has: t.Set[str], more_has: t.Set[str]):\n",
    "        self._less_has = less_has\n",
    "        self._more_has = more_has\n",
    "\n",
    "    def mask(self, less_label_set: t.Set[str], df: pd.DataFrame) -> t.Optional[pd.Series]:\n",
    "        if not self._less_has.issubset(less_label_set):\n",
    "            return None\n",
    "        base_label_set = less_label_set - self._less_has\n",
    "        mask: t.Optional[pd.Series] = None\n",
    "        for label in base_label_set | self._more_has:\n",
    "            mask = mask & (df[label] == 1) if mask is not None else (df[label] == 1)\n",
    "        assert mask is not None\n",
    "        return mask\n",
    "\n",
    "\n",
    "more_condition_list = [\n",
    "    # SimpleMoreCondition(),\n",
    "    # Inferred directly from the valid data.\n",
    "    ComparisonBasedMoreCondition({L.INSULT}, {L.SEVERE_TOXIC}),\n",
    "    ComparisonBasedMoreCondition({L.IDENTITY_HATE}, {L.SEVERE_TOXIC}),\n",
    "    ComparisonBasedMoreCondition({L.TOXIC}, {L.OBSCENE, L.INSULT}),\n",
    "    ComparisonBasedMoreCondition({L.INSULT}, {L.IDENTITY_HATE}),\n",
    "    ComparisonBasedMoreCondition({L.TOXIC}, {L.IDENTITY_HATE}),\n",
    "    ComparisonBasedMoreCondition({L.THREAT}, {L.OBSCENE, L.INSULT}),\n",
    "    ComparisonBasedMoreCondition({L.INSULT}, {L.SEVERE_TOXIC, L.OBSCENE}),\n",
    "    ComparisonBasedMoreCondition({L.OBSCENE}, {L.IDENTITY_HATE}),\n",
    "    # Inferred from the transitivity of < operation.\n",
    "    # ComparisonBasedMoreCondition({L.TOXIC}, {L.SEVERE_TOXIC}),\n",
    "    # ComparisonBasedMoreCondition({L.THREAT}, {L.OBSCENE, L.SEVERE_TOXIC}),\n",
    "    # ComparisonBasedMoreCondition({L.THREAT}, {L.OBSCENE, L.IDENTITY_HATE}),\n",
    "    # ComparisonBasedMoreCondition({L.OBSCENE}, {L.SEVERE_TOXIC}),\n",
    "    # ComparisonBasedMoreCondition({L.THREAT}, {L.SEVERE_TOXIC, L.INSULT}),\n",
    "    # ComparisonBasedMoreCondition({L.THREAT}, {L.IDENTITY_HATE, L.INSULT}),\n",
    "    # Inferred from the common sense.\n",
    "    # ComparisonBasedMoreCondition({L.TOXIC}, {L.THREAT}),\n",
    "    # ComparisonBasedMoreCondition({L.OBSCENE}, {L.THREAT}),\n",
    "]\n",
    "\n",
    "\n",
    "def _label_set(readable_label_str: str) -> t.Set[str]:\n",
    "    return set(readable_label_str.split(' ')) if readable_label_str else set()\n",
    "\n",
    "\n",
    "def mine_pairs(\n",
    "        df: pd.DataFrame,\n",
    "        more_condition_list: t.List[MoreCondition],\n",
    "        non_toxic_ratio: float = 0.1,\n",
    "        max_n_flags_distance: int = 2,\n",
    "        toxic_max_pairs_per_sample: int = 3,\n",
    "        non_toxic_max_pairs_per_sample: int = 3) -> pd.DataFrame:\n",
    "    simple_more_condition = SimpleMoreCondition()\n",
    "    pair_row_list = []\n",
    "    num_no_pairs = 0\n",
    "    toxic_df = df[df['n_flags'] > 0]\n",
    "    non_toxic_df = df[df['n_flags'] == 0]\n",
    "    less_df = pd.concat([\n",
    "        toxic_df,\n",
    "        non_toxic_df.sample(frac=1.0).iloc[:int(len(toxic_df) * non_toxic_ratio)]\n",
    "    ])\n",
    "    it = tqdm(less_df.iterrows(), total=len(less_df))\n",
    "    for idx, less_row in it:\n",
    "        less_label_set = _label_set(less_row['readable_label'])\n",
    "        base_mask = (df.index != idx) \\\n",
    "            & (df['readable_label'] != less_row['readable_label']) \\\n",
    "            & (df['n_flags'] >= less_row['n_flags']) \\\n",
    "            & (df['n_flags'] <= less_row['n_flags'] + max_n_flags_distance)\n",
    "        cond_mask = None\n",
    "        for c in more_condition_list:\n",
    "            c_mask = c.mask(less_label_set, df)\n",
    "            if c_mask is not None:\n",
    "                cond_mask = cond_mask | c_mask if cond_mask is not None else c_mask\n",
    "        if cond_mask is None and less_row['n_flags'] == 0:\n",
    "           cond_mask = simple_more_condition.mask(less_label_set, df)\n",
    "        # if cond_mask is None:\n",
    "        #     raise RuntimeError(f'Conditions failed with label set: {less_label_set}')\n",
    "        if cond_mask is None:\n",
    "            continue\n",
    "        more_df = df[base_mask & cond_mask]\n",
    "        if len(more_df):\n",
    "            for _, more_row in more_df.sample(\n",
    "                    n=min(len(more_df), toxic_max_pairs_per_sample if less_row['n_flags'] > 0 else non_toxic_max_pairs_per_sample)).iterrows():\n",
    "                pair_row_list.append({\n",
    "                    'less_toxic': less_row['comment_text'],\n",
    "                    'more_toxic': more_row['comment_text'],\n",
    "                    'less_toxic_readable_label': less_row['readable_label'],\n",
    "                    'less_toxic_bitmap_label': less_row['bitmap_label'],\n",
    "                    'more_toxic_readable_label': more_row['readable_label'],\n",
    "                    'more_toxic_bitmap_label': more_row['bitmap_label'],\n",
    "                    'is_subset': int(less_label_set.issubset(_label_set(more_row['readable_label']))),\n",
    "                })\n",
    "        else:\n",
    "            num_no_pairs += 1\n",
    "        it.set_description(f'num_pairs: {len(pair_row_list)}, num_no_pairs: {num_no_pairs}')\n",
    "    return pd.DataFrame(pair_row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_df = mine_pairs(df=all_df, more_condition_list=more_condition_list)\n",
    "pair_df = mine_pairs(\n",
    "    df=all_df,\n",
    "    more_condition_list=more_condition_list,\n",
    "    non_toxic_ratio=0.25,\n",
    "    max_n_flags_distance=3,\n",
    "    toxic_max_pairs_per_sample=9,\n",
    "    non_toxic_max_pairs_per_sample=3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
