{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import functools\n",
    "import itertools\n",
    "import random\n",
    "import statistics\n",
    "import typing as t\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as torch_f\n",
    "import typing_extensions as t_ext\n",
    "from textaugment import Wordnet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers.models.auto.configuration_auto import AutoConfig\n",
    "from transformers.models.auto.modeling_auto import AutoModel\n",
    "from transformers.models.auto.tokenization_auto import AutoTokenizer\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TokenizedText(t_ext.TypedDict):\n",
    "    input_ids: torch.Tensor\n",
    "    attention_mask: torch.Tensor\n",
    "\n",
    "\n",
    "def _preprocess_tokenizer_output(output: t.Dict[str, t.Any]) -> _TokenizedText:\n",
    "    return {\n",
    "        'input_ids': torch.tensor(output['input_ids']),\n",
    "        'attention_mask': torch.tensor(output['attention_mask']),\n",
    "    }\n",
    "\n",
    "\n",
    "def _split_str_to_chunk_list(s: str, chunk_size: int) -> t.List[str]:\n",
    "    chunk_list = []\n",
    "    chunk = []\n",
    "    for token in s.split(' '):\n",
    "        chunk.append(token)\n",
    "        if len(chunk) >= chunk_size:\n",
    "            chunk_list.append(' '.join(chunk))\n",
    "            chunk.clear()\n",
    "    if chunk:\n",
    "        chunk_list.append(' '.join(chunk))\n",
    "    return chunk_list\n",
    "\n",
    "\n",
    "def predict_collate_fn(\n",
    "        sample_list: t.List[t.Tuple[str, _TokenizedText]]\n",
    "        ) -> t.Tuple[t.List[str], _TokenizedText, t.List[slice]]:\n",
    "    curr_pos = 0\n",
    "\n",
    "    idx_list: t.List[str] = []\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    slice_list: t.List[slice] = []\n",
    "    \n",
    "    for sample in sample_list:\n",
    "        idx_list.append(sample[0])\n",
    "        input_ids, attention_mask = sample[1]['input_ids'], sample[1]['attention_mask']\n",
    "        input_ids_list.append(input_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        slice_list.append(slice(curr_pos, curr_pos + input_ids.shape[0]))\n",
    "        curr_pos += input_ids.shape[0]\n",
    "\n",
    "    tokenized_collated: _TokenizedText = {\n",
    "        'input_ids': torch.cat(input_ids_list, dim=0),\n",
    "        'attention_mask': torch.cat(attention_mask_list, dim=0),\n",
    "    }\n",
    "\n",
    "    return idx_list, tokenized_collated, slice_list\n",
    "\n",
    "\n",
    "class PredictDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            df: pd.DataFrame,\n",
    "            tokenizer: AutoTokenizer,\n",
    "            max_len: int,\n",
    "            augmentation_list: t.Optional[t.List[t.Callable[[str], str]]] = None) -> None:\n",
    "        super().__init__()\n",
    "        self._df = df\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_len = max_len\n",
    "        self._augmentation_list = augmentation_list if augmentation_list is not None else []\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> t.Tuple[str, _TokenizedText]:\n",
    "        record = self._df.iloc[idx]\n",
    "        comment_id, text = str(record['comment_id']), str(record['text'])\n",
    "\n",
    "        for aug in self._augmentation_list:\n",
    "            text = aug(text)\n",
    "\n",
    "        input_ids_list, attention_mask_list = [], []\n",
    "        for chunk in _split_str_to_chunk_list(text, chunk_size=self._max_len):\n",
    "            tokenized_chunk = _preprocess_tokenizer_output(self._tokenizer(\n",
    "                chunk,\n",
    "                add_special_tokens=True,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self._max_len,\n",
    "                return_attention_mask=True))  # type: ignore\n",
    "            input_ids_list.append(tokenized_chunk['input_ids'])\n",
    "            attention_mask_list.append(tokenized_chunk['attention_mask'])\n",
    "\n",
    "        tokenized_text: _TokenizedText = {\n",
    "            'input_ids': torch.stack(input_ids_list, dim=0),\n",
    "            'attention_mask': torch.stack(attention_mask_list, dim=0),\n",
    "        }\n",
    "\n",
    "        return comment_id, tokenized_text\n",
    "\n",
    "\n",
    "class NoChunksPredictDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer, max_len: int) -> None:\n",
    "        super().__init__()\n",
    "        self._df = df\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> t.Tuple[str, _TokenizedText]:\n",
    "        record = self._df.iloc[idx]\n",
    "        comment_id, text = str(record['comment_id']), str(record['text'])\n",
    "\n",
    "        tokenized_text = _preprocess_tokenizer_output(self._tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self._max_len,\n",
    "            return_attention_mask=True))  # type: ignore\n",
    "\n",
    "        return comment_id, tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class ModelConfig(t.NamedTuple):\n",
    "    name: str\n",
    "    model: Model\n",
    "    tokenizer: AutoTokenizer\n",
    "\n",
    "\n",
    "def import_checkpoint(model: torch.nn.Module, checkpoint: str, device: str):\n",
    "    state_dict = torch.load(checkpoint, map_location=device)\n",
    "    # print('state dict keys:', state_dict.keys())\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CCC 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ccc_2017_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AttentionRegressor(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_features: int) -> None:\n",
    "        super().__init__()\n",
    "        self.attention = torch.nn.Linear(in_features=in_features, out_features=in_features, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        weight = self.attention(x)\n",
    "        return (x * torch_f.softmax(weight, dim=1)).sum(dim=1)\n",
    "\n",
    "\n",
    "class _CCC2017M1Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, num_classes: int):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.blind_regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(output_logits, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 1),\n",
    "            torch.nn.Sigmoid())\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, num_classes))\n",
    "        self.regressor = _AttentionRegressor(in_features=num_classes + 1)\n",
    "\n",
    "    def forward_scores(self, blind_reg_output: torch.Tensor, label_preds: torch.Tensor) -> torch.Tensor:\n",
    "        return self.regressor(torch.cat([torch.sigmoid(label_preds), blind_reg_output], dim=1))\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> t.Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        _, pooled_output = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        blind_reg_output = self.blind_regressor(pooled_output)\n",
    "        label_preds = self.classifier(pooled_output)\n",
    "        scores = self.forward_scores(blind_reg_output, label_preds)\n",
    "        return blind_reg_output, label_preds, scores\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)[2]\n",
    "\n",
    "\n",
    "def load_ccc2017_m1(device: str) -> ModelConfig:\n",
    "    model = _CCC2017M1Model('roberta-base', 768, 6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/ccc-2017-multilabel-v3-cls-att-blind-reg.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='ccc-2017-multilabel-v3-cls-att-blind-reg',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ccc_2017_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _M2WeightedAverageLinearRegressor(torch.nn.Linear):\n",
    "\n",
    "    def __init__(self, in_features: int, device: t.Optional[str] = None, dtype: t.Optional[str] = None):\n",
    "        super().__init__(in_features=in_features, out_features=1, bias=False, device=device, dtype=dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch_f.linear(x, torch_f.softmax(self.weight, dim=1), self.bias)\n",
    "\n",
    "\n",
    "class _CCC2017M2Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, num_classes: int):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, num_classes))\n",
    "        self.regressor = _M2WeightedAverageLinearRegressor(in_features=num_classes)\n",
    "\n",
    "    def forward_scores(self, label_preds: torch.Tensor) -> torch.Tensor:\n",
    "        return self.regressor(label_preds)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        _, pooled_output = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        label_preds = self.classifier(pooled_output)\n",
    "        scores = self.forward_scores(torch.sigmoid(label_preds))\n",
    "        return label_preds, scores\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)[1]\n",
    "\n",
    "\n",
    "def load_ccc2017_m2(device: str) -> ModelConfig:\n",
    "    model = _CCC2017M2Model('roberta-base', 768, 6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/ccc-2017-multilabel-harder-cls-loss_0p5-v2.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='ccc-2017-multilabel-harder-cls-loss_0p5-v2',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ccc_2017_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _WeightedAverageLinearRegressor(torch.nn.Linear):\n",
    "\n",
    "    def __init__(self, in_features: int, device: t.Optional[str] = None, dtype: t.Optional[str] = None):\n",
    "        super().__init__(in_features=in_features, out_features=1, bias=False, device=device, dtype=dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch_f.linear(x, torch_f.softmax(self.weight, dim=1), self.bias)\n",
    "\n",
    "\n",
    "class _CCC2017M3Model(Model):\n",
    "    \"\"\"\n",
    "    ccc-2017-multilabel-harder-cls-loss_0p5-v2-valfreq_dynamic_v1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, num_classes))\n",
    "        self.regressor = _WeightedAverageLinearRegressor(in_features=num_classes)\n",
    "\n",
    "    def forward_scores(self, label_preds: torch.Tensor) -> torch.Tensor:\n",
    "        return self.regressor(label_preds)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        _, pooled_output = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        label_preds = self.classifier(pooled_output)\n",
    "        scores = self.forward_scores(torch.sigmoid(label_preds))\n",
    "        return label_preds, scores\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)[1]\n",
    "\n",
    "\n",
    "def load_ccc2017_m3(device: str) -> ModelConfig:\n",
    "    model = _CCC2017M3Model('roberta-base', 768, 6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/ccc-2017-multilabel-harder-cls-loss_0p5-v2-valfreq_dynamic_v1.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='ccc-2017-multilabel-harder-cls-loss_0p5-v2-valfreq_dynamic_v1',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ccc_2017_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _CCC2017M4WeightedAverageLinearRegressor(torch.nn.Linear):\n",
    "\n",
    "    def __init__(self, in_features: int, device: t.Optional[str] = None, dtype: t.Optional[str] = None):\n",
    "        super().__init__(in_features=in_features, out_features=1, bias=False, device=device, dtype=dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch_f.linear(x, torch_f.softmax(self.weight, dim=1), self.bias)\n",
    "\n",
    "\n",
    "class _CCC2017M4Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, num_classes: int):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, num_classes))\n",
    "        self.regressor = _CCC2017M4WeightedAverageLinearRegressor(in_features=num_classes)\n",
    "\n",
    "    def forward_scores(self, label_preds: torch.Tensor) -> torch.Tensor:\n",
    "        return self.regressor(label_preds)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        _, pooled_output = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        label_preds = self.classifier(pooled_output)\n",
    "        scores = self.forward_scores(torch.sigmoid(label_preds))\n",
    "        return label_preds, scores\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)[1]\n",
    "\n",
    "\n",
    "def load_ccc2017_m4(device: str) -> ModelConfig:\n",
    "    model = _CCC2017M4Model('roberta-base', 768, 6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/ccc-2017-multilabel-harder-cls-loss_0p5_pow4-margin_0p3-seed_42.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='ccc-2017-multilabel-harder-cls-loss_0p5_pow4-margin_0p3-seed_42',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UBTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ubtc_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _UBTCM1Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, num_classes: int):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.feature_regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(output_logits, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, num_classes),\n",
    "            torch.nn.Sigmoid())\n",
    "        self.score_regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_classes, 1),\n",
    "            torch.nn.Sigmoid())\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        _, pooled_output = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        features = self.feature_regressor(pooled_output)\n",
    "        return features, self.score_regressor(features)\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)[1]\n",
    "\n",
    "\n",
    "def load_ubtc_m1(device: str) -> ModelConfig:\n",
    "    model = _UBTCM1Model('unitary/unbiased-toxic-roberta', 768, 7)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/ubtc-multireg-w50-cos_warmup-opt-2ep-ut_roberta-valfreq_dynamic_v1-seed_42.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='ubtc-multireg-w50-cos_warmup-opt-2ep-ut_roberta-seed_42',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('unitary/unbiased-toxic-roberta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ubtc_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _UBTCM2Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, dropout: float):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(checkpoint)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        self.roberta = AutoModel.from_pretrained(checkpoint, config=config)  \n",
    "            \n",
    "        self.attention = torch.nn.Sequential(            \n",
    "            torch.nn.Linear(output_logits, 512),            \n",
    "            torch.nn.Tanh(),                       \n",
    "            torch.nn.Linear(512, 1),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = torch.nn.Sequential(                        \n",
    "            torch.nn.Linear(output_logits, 1),\n",
    "            torch.nn.Tanh(),                      \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        roberta_output = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)        \n",
    "\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "        last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "def load_ubtc_m2(device: str) -> ModelConfig:\n",
    "    model = _UBTCM2Model('unitary/unbiased-toxic-roberta', 768, 0.6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/ubtc-pure_reg-w50-cos_warmup_opt-2ep-att-ut_roberta-seed_42.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='ubtc-pure_reg-w50-cos_warmup_opt-2ep-att-ut_roberta-seed_42',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('unitary/unbiased-toxic-roberta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ruddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ruddit_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _RudditM1Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        return self.regressor(pooled_output)\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "def load_ruddit_m1(device: str) -> ModelConfig:\n",
    "    model = _RudditM1Model('roberta-base', 768, 0.6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/ruddit-v3-mse-2ep-pure_reg.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='ruddit-v3-mse-2ep-pure_reg',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ruddit_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _RudditM2Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 256),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(256, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        return self.regressor(pooled_output)\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "def load_ruddit_m2(device: str) -> ModelConfig:\n",
    "    model = _RudditM2Model('unitary/unbiased-toxic-roberta', 768, 0.6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/ruddit-v3-mse-2ep-pure_reg-unbiased_toxic_roberta-2layer_reg.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='ruddit-v3-mse-2ep-pure_reg-unbiased_toxic_roberta-2layer_reg',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('unitary/unbiased-toxic-roberta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wiki Talk Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wiki_talk_labels_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _WikiTalkLabelsM1Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, dropout: float):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(output_logits, 256),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(256, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        return self.regressor(pooled_output)\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "def load_wiki_talk_labels_m1(device: str) -> ModelConfig:\n",
    "    model = _WikiTalkLabelsM1Model('roberta-base', 768, 0.6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/wiki-talk-labels-v1-1ep.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='wiki-talk-labels-v1-1ep',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wiki_talk_labels_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _WikiTalkLabelsM2Model(Model):\n",
    "    def __init__(self, checkpoint: str, output_logits: int, dropout: float):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(checkpoint)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        self.roberta = AutoModel.from_pretrained(checkpoint, config=config)  \n",
    "            \n",
    "        self.attention = torch.nn.Sequential(            \n",
    "            torch.nn.Linear(output_logits, 512),            \n",
    "            torch.nn.Tanh(),                       \n",
    "            torch.nn.Linear(512, 1),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = torch.nn.Sequential(                        \n",
    "            torch.nn.Linear(output_logits, 1),\n",
    "            torch.nn.Tanh(),                      \n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        roberta_output = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)        \n",
    "\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "        last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)\n",
    "\n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "def load_wiki_talk_labels_m2(device: str) -> ModelConfig:\n",
    "    model = _WikiTalkLabelsM2Model('roberta-base', 768, 0.6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/wiki-talk-labels-v1-1ep-att.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='wiki-talk-labels-v1-1ep-att',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offenseval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### offenseval_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _OffensevalM1Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        return self.regressor(pooled_output)\n",
    "    \n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "def load_offenseval_m1(device: str) -> ModelConfig:\n",
    "    model = _OffensevalM1Model('roberta-base', 768, 0.6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/offenseval-2020-v2-pure_reg-mse-1_ep-64_valcycles-lr_2e5.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='offenseval-2020-v2-pure_reg-mse-1_ep-64_valcycles-lr_2e5',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### offenseval_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _OffensevalM2Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, dropout: float):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        return self.regressor(pooled_output)\n",
    "    \n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "def load_offenseval_m2(device: str) -> ModelConfig:\n",
    "    model = _OffensevalM2Model('unitary/unbiased-toxic-roberta', 768, 0.6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/offenseval-2020-v2-pure_reg-mse-1_ep-64_valcycles-lr_2e5-backbone_utr.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='offenseval-2020-v2-pure_reg-mse-1_ep-64_valcycles-lr_2e5-backbone_utr',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('unitary/unbiased-toxic-roberta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _C3M1Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, dropout: float):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 256),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(256, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        return self.regressor(pooled_output)\n",
    "    \n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "def load_c3_m1(device: str) -> ModelConfig:\n",
    "    model = _C3M1Model('roberta-base', 768, 0.6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/c3-v1-2ep.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='c3-v1-2ep',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _C3M2Model(Model):\n",
    "\n",
    "    def __init__(self, checkpoint: str, output_logits: int, dropout: float):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            # torch.nn.LayerNorm(output_logits),\n",
    "            torch.nn.Linear(output_logits, 256),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(256, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "        return self.regressor(pooled_output)\n",
    "    \n",
    "    def predict_scores(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(input_ids, attention_mask)\n",
    "\n",
    "\n",
    "def load_c3_m2(device: str) -> ModelConfig:\n",
    "    model = _C3M2Model('roberta-base', 768, 0.6)\n",
    "    import_checkpoint(model, '/home/jovyan/jigsaw-toxic/models/c3-v1-2ep-valfreq_10.pt', device=device)\n",
    "    return ModelConfig(\n",
    "        name='c3-v1-2ep-valfreq_10',\n",
    "        model=model,\n",
    "        tokenizer=AutoTokenizer.from_pretrained('roberta-base'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predict_iteration(\n",
    "        data_loader: DataLoader,\n",
    "        model: Model,\n",
    "        model_name: str,\n",
    "        device: str) -> np.ndarray:\n",
    "    model.eval()\n",
    "    score_list = []\n",
    "    with torch.no_grad():\n",
    "        it = tqdm(data_loader, desc=model_name)\n",
    "        for _, tokenized_text, slice_list in it:\n",
    "            score_tensor = model.predict_scores(\n",
    "                tokenized_text['input_ids'].to(device),\n",
    "                tokenized_text['attention_mask'].to(device),)\n",
    "            score_tensor = torch.cat([torch.max(score_tensor[s], dim=0, keepdim=True)[0] for s in slice_list], dim=0)\n",
    "            score_list.extend(score_tensor.cpu().flatten().tolist())\n",
    "    return torch.tensor(score_list).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_model(\n",
    "        valid_df: pd.DataFrame,\n",
    "        batch_size: int,\n",
    "        model_getter: t.Callable[[str], ModelConfig],\n",
    "        max_len: int,\n",
    "        num_workers: int,\n",
    "        device: str,\n",
    "        num_iterations: int = 3) -> np.ndarray:\n",
    "    model_config = model_getter(device)\n",
    "    model = model_config.model.to(device)\n",
    "    score_arr_list = []\n",
    "    wordnet = Wordnet(v=True, n=True, p=0.5)\n",
    "    for i in range(num_iterations):\n",
    "        aug_list = []\n",
    "        if i < num_iterations - 1:\n",
    "            aug_list.append(lambda text: wordnet.augment(text))\n",
    "        dataset = PredictDataset(\n",
    "            df=valid_df,\n",
    "            tokenizer=model_config.tokenizer,\n",
    "            max_len=max_len,\n",
    "            augmentation_list=aug_list)\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=predict_collate_fn,  # type: ignore\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=device.startswith('cuda'))\n",
    "        score_arr = do_predict_iteration(data_loader=data_loader, model=model, model_name=model_config.name, device=device)\n",
    "        score_arr_list.append(score_arr)\n",
    "    return np.stack(score_arr_list, axis=0).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = t.cast(pd.DataFrame, pd.read_csv('/home/jovyan/jigsaw-toxic/data/jigsaw-toxic-severity-rating/valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_to_eval_format(valid_df: pd.DataFrame) -> t.Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    comment_id_dict: t.Dict[int, str] = {}\n",
    "    valid_row_list = []\n",
    "    for _, row in valid_df.iterrows():\n",
    "        more_toxic, less_toxic = str(row['more_toxic']), str(row['less_toxic'])\n",
    "        more_toxic_id, less_toxic_id = hash(more_toxic), hash(less_toxic)\n",
    "        comment_id_dict[more_toxic_id] = more_toxic\n",
    "        comment_id_dict[less_toxic_id] = less_toxic\n",
    "        valid_row_list.append({\n",
    "            'more_toxic_id': more_toxic_id,\n",
    "            'less_toxic_id': less_toxic_id,\n",
    "        })\n",
    "    eval_row_list = [{'comment_id': comment_id, 'text': text} for comment_id, text in comment_id_dict.items()]\n",
    "    return pd.DataFrame(valid_row_list), pd.DataFrame(eval_row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df, eval_df = valid_to_eval_format(valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ccc_2017_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc2017_m1_score_arr = predict_by_model(\n",
    "    valid_df=eval_df,\n",
    "    batch_size=8,\n",
    "    model_getter=load_ccc2017_m1,\n",
    "    num_workers=8,\n",
    "    max_len=256,\n",
    "    device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ccc_2017_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccc2017_m2_score_arr = predict_by_model(\n",
    "#     valid_df=eval_df,\n",
    "#     batch_size=8,\n",
    "#     model_getter=load_ccc2017_m2,\n",
    "#     num_workers=8,\n",
    "#     max_len=256,\n",
    "#     device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ccc_2017_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc2017_m3_score_arr = predict_by_model(\n",
    "    valid_df=eval_df,\n",
    "    batch_size=8,\n",
    "    model_getter=load_ccc2017_m3,\n",
    "    num_workers=8,\n",
    "    max_len=256,\n",
    "    device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ccc_2017_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccc2017_m4_score_arr = predict_by_model(\n",
    "#     valid_df=eval_df,\n",
    "#     batch_size=8,\n",
    "#     model_getter=load_ccc2017_m4,\n",
    "#     num_workers=8,\n",
    "#     max_len=256,\n",
    "#     device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ubtc_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubtc_m1_score_arr = predict_by_model(\n",
    "#     valid_df=eval_df,\n",
    "#     batch_size=8,\n",
    "#     model_getter=load_ubtc_m1,\n",
    "#     num_workers=8,\n",
    "#     max_len=256,\n",
    "#     device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ubtc_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubtc_m2_score_arr = predict_by_model(\n",
    "#     valid_df=eval_df,\n",
    "#     batch_size=8,\n",
    "#     model_getter=load_ubtc_m2,\n",
    "#     num_workers=8,\n",
    "#     max_len=256,\n",
    "#     device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ruddit_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruddit_m1_score_arr = predict_by_model(\n",
    "    valid_df=eval_df,\n",
    "    batch_size=8,\n",
    "    model_getter=load_ruddit_m1,\n",
    "    num_workers=8,\n",
    "    max_len=256,\n",
    "    device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ruddit_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruddit_m2_score_arr = predict_by_model(\n",
    "    valid_df=eval_df,\n",
    "    batch_size=8,\n",
    "    model_getter=load_ruddit_m2,\n",
    "    num_workers=8,\n",
    "    max_len=256,\n",
    "    device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wiki_talk_labels_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_talk_labels_m1_score_arr = predict_by_model(\n",
    "    valid_df=eval_df,\n",
    "    batch_size=8,\n",
    "    model_getter=load_wiki_talk_labels_m1,\n",
    "    num_workers=8,\n",
    "    max_len=256,\n",
    "    device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wiki_talk_labels_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_talk_labels_m2_score_arr = predict_by_model(\n",
    "#     valid_df=eval_df,\n",
    "#     batch_size=8,\n",
    "#     model_getter=load_wiki_talk_labels_m2,\n",
    "#     num_workers=8,\n",
    "#     max_len=256,\n",
    "#     device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### offenseval_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offenseval_m1_score_arr = predict_by_model(\n",
    "#     valid_df=eval_df,\n",
    "#     batch_size=8,\n",
    "#     model_getter=load_offenseval_m1,\n",
    "#     num_workers=8,\n",
    "#     max_len=256,\n",
    "#     device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### offenseval_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offenseval_m2_score_arr = predict_by_model(\n",
    "#     valid_df=eval_df,\n",
    "#     batch_size=8,\n",
    "#     model_getter=load_offenseval_m2,\n",
    "#     num_workers=8,\n",
    "#     max_len=256,\n",
    "#     device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c3_m1_score_arr = predict_by_model(\n",
    "#     valid_df=eval_df,\n",
    "#     batch_size=8,\n",
    "#     model_getter=load_c3_m1,\n",
    "#     num_workers=8,\n",
    "#     max_len=256,\n",
    "#     device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c3_m2_score_arr = predict_by_model(\n",
    "#     valid_df=eval_df,\n",
    "#     batch_size=8,\n",
    "#     model_getter=load_c3_m2,\n",
    "#     num_workers=8,\n",
    "#     max_len=256,\n",
    "#     device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['score_ccc2017_m1'] = ccc2017_m1_score_arr\n",
    "# eval_df['score_ccc2017_m2'] = ccc2017_m2_score_arr\n",
    "eval_df['score_ccc2017_m3'] = ccc2017_m3_score_arr\n",
    "# eval_df['score_ccc2017_m4'] = ccc2017_m4_score_arr\n",
    "# eval_df['score_ubtc_m1'] = ubtc_m1_score_arr\n",
    "# eval_df['score_ubtc_m1'] = ubtc_m2_score_arr\n",
    "eval_df['score_ruddit_m1'] = ruddit_m1_score_arr\n",
    "eval_df['score_ruddit_m2'] = ruddit_m2_score_arr\n",
    "eval_df['score_wiki_talk_labels_m1'] = wiki_talk_labels_m1_score_arr\n",
    "# eval_df['score_wiki_talk_labels_m2'] = wiki_talk_labels_m2_score_arr\n",
    "# eval_df['offenseval_m1'] = offenseval_m1_score_arr\n",
    "# eval_df['offenseval_m2'] = offenseval_m2_score_arr\n",
    "# eval_df['c3_m1'] = c3_m1_score_arr\n",
    "# eval_df['c3_m2'] = c3_m2_score_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv('/home/jovyan/jigsaw-toxic/scores/external_datasets_20220207_translate.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = t.cast(pd.DataFrame, pd.read_csv('/home/jovyan/jigsaw-toxic/scores/external_datasets_20220207.csv'))\n",
    "ccc2017_m1_score_arr = eval_df['score_ccc2017_m1'].to_numpy()\n",
    "ccc2017_m2_score_arr = eval_df['score_ccc2017_m2'].to_numpy()\n",
    "ccc2017_m3_score_arr = eval_df['score_ccc2017_m3'].to_numpy()\n",
    "ccc2017_m4_score_arr = eval_df['score_ccc2017_m4'].to_numpy()\n",
    "ubtc_m1_score_arr = eval_df['score_ubtc_m1'].to_numpy()\n",
    "ubtc_m2_score_arr = eval_df['score_ubtc_m1'].to_numpy()\n",
    "ruddit_m1_score_arr = eval_df['score_ruddit_m1'].to_numpy()\n",
    "ruddit_m2_score_arr = eval_df['score_ruddit_m2'].to_numpy()\n",
    "wiki_talk_labels_m1_score_arr = eval_df['score_wiki_talk_labels_m1'].to_numpy()\n",
    "wiki_talk_labels_m2_score_arr = eval_df['score_wiki_talk_labels_m2'].to_numpy()\n",
    "offenseval_m1_score_arr = eval_df['offenseval_m1']\n",
    "offenseval_m2_score_arr = eval_df['offenseval_m2']\n",
    "c3_m1_score_arr = eval_df['c3_m1']\n",
    "c3_m2_score_arr = eval_df['c3_m2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_valid(valid_df: pd.DataFrame, eval_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    valid_df = valid_df.copy()\n",
    "    text_to_comment_id = {str(row['text']): int(row['comment_id']) for _, row in eval_df.iterrows()}\n",
    "    valid_df['more_toxic_id'] = valid_df['more_toxic'].apply(lambda text: text_to_comment_id[text])\n",
    "    valid_df['less_toxic_id'] = valid_df['less_toxic'].apply(lambda text: text_to_comment_id[text])\n",
    "    return valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = t.cast(pd.DataFrame, pd.read_csv('/home/jovyan/jigsaw-toxic/data/jigsaw-toxic-severity-rating/valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>certainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I think people say its not so absurd, because ...</td>\n",
       "      <td>Re Vandalism. . . .  that is because the user ...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must have the lowest IQ of anyone on wikip...</td>\n",
       "      <td>Wha's a reliable source mike? Something that c...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks for removing more of his anonymous, un...</td>\n",
       "      <td>To Bad\\nyou dont have the balls to sign in, I ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\n\\nActually, it clearly does not involve pow...</td>\n",
       "      <td>, 18 November 2006 (UTC)\\n\\nWell comrade. Look...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are not cool \\n\\nYou are the most hated f...</td>\n",
       "      <td>\"== Hey Fuck-head==\\nHey, just wanted to say \"...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10103</th>\n",
       "      <td>Heeeeeeeeeeeeeeyyyyyyyyyyyy dude! Sup!</td>\n",
       "      <td>you deleted my page \\nand i am extrememly mad ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>ATTENTION:''''''\\n\\nANYONE WHO OPPOSES MY OPIN...</td>\n",
       "      <td>suck dick u disrespectful swearing wank!!</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>Oh yah, and Bayerischermann is another guy try...</td>\n",
       "      <td>Thanks. Also thanks for freezing the article. ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10106</th>\n",
       "      <td>I had to chop out a section specifically compa...</td>\n",
       "      <td>\"\\n\\nHorrifyingly enough, \"\"ritualistic penis ...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>Please kill yourself.</td>\n",
       "      <td>That's a load of crap. You are letting trolls ...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              less_toxic  \\\n",
       "0      I think people say its not so absurd, because ...   \n",
       "1      You must have the lowest IQ of anyone on wikip...   \n",
       "2       Thanks for removing more of his anonymous, un...   \n",
       "3      \"\\n\\nActually, it clearly does not involve pow...   \n",
       "4       You are not cool \\n\\nYou are the most hated f...   \n",
       "...                                                  ...   \n",
       "10103          Heeeeeeeeeeeeeeyyyyyyyyyyyy dude! Sup!      \n",
       "10104  ATTENTION:''''''\\n\\nANYONE WHO OPPOSES MY OPIN...   \n",
       "10105  Oh yah, and Bayerischermann is another guy try...   \n",
       "10106  I had to chop out a section specifically compa...   \n",
       "10107                            Please kill yourself.     \n",
       "\n",
       "                                              more_toxic  certainty  \n",
       "0      Re Vandalism. . . .  that is because the user ...   0.666667  \n",
       "1      Wha's a reliable source mike? Something that c...   1.000000  \n",
       "2      To Bad\\nyou dont have the balls to sign in, I ...   1.000000  \n",
       "3      , 18 November 2006 (UTC)\\n\\nWell comrade. Look...   0.666667  \n",
       "4      \"== Hey Fuck-head==\\nHey, just wanted to say \"...   1.000000  \n",
       "...                                                  ...        ...  \n",
       "10103  you deleted my page \\nand i am extrememly mad ...   1.000000  \n",
       "10104          suck dick u disrespectful swearing wank!!   1.000000  \n",
       "10105  Thanks. Also thanks for freezing the article. ...   1.000000  \n",
       "10106  \"\\n\\nHorrifyingly enough, \"\"ritualistic penis ...   0.666667  \n",
       "10107  That's a load of crap. You are letting trolls ...   0.666667  \n",
       "\n",
       "[10108 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = process_valid(valid_df, eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>certainty</th>\n",
       "      <th>more_toxic_id</th>\n",
       "      <th>less_toxic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I think people say its not so absurd, because ...</td>\n",
       "      <td>Re Vandalism. . . .  that is because the user ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8871839934638558331</td>\n",
       "      <td>-4761684140996904817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must have the lowest IQ of anyone on wikip...</td>\n",
       "      <td>Wha's a reliable source mike? Something that c...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1637230891836237423</td>\n",
       "      <td>-7956336680269787100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks for removing more of his anonymous, un...</td>\n",
       "      <td>To Bad\\nyou dont have the balls to sign in, I ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4417861673610340204</td>\n",
       "      <td>-9111912784081641002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\n\\nActually, it clearly does not involve pow...</td>\n",
       "      <td>, 18 November 2006 (UTC)\\n\\nWell comrade. Look...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>538743044374089943</td>\n",
       "      <td>1009349673192730117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are not cool \\n\\nYou are the most hated f...</td>\n",
       "      <td>\"== Hey Fuck-head==\\nHey, just wanted to say \"...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8395351920140636842</td>\n",
       "      <td>-8465358288158148543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10103</th>\n",
       "      <td>Heeeeeeeeeeeeeeyyyyyyyyyyyy dude! Sup!</td>\n",
       "      <td>you deleted my page \\nand i am extrememly mad ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-587030008757665900</td>\n",
       "      <td>-6157675788695320718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>ATTENTION:''''''\\n\\nANYONE WHO OPPOSES MY OPIN...</td>\n",
       "      <td>suck dick u disrespectful swearing wank!!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6392442731289747528</td>\n",
       "      <td>-2454273551981799926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>Oh yah, and Bayerischermann is another guy try...</td>\n",
       "      <td>Thanks. Also thanks for freezing the article. ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3818525241629339148</td>\n",
       "      <td>7225573479073611155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10106</th>\n",
       "      <td>I had to chop out a section specifically compa...</td>\n",
       "      <td>\"\\n\\nHorrifyingly enough, \"\"ritualistic penis ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-2636152035767601275</td>\n",
       "      <td>-3759500075766815347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>Please kill yourself.</td>\n",
       "      <td>That's a load of crap. You are letting trolls ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-8122249264644078195</td>\n",
       "      <td>4348547404275874995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10108 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              less_toxic  \\\n",
       "0      I think people say its not so absurd, because ...   \n",
       "1      You must have the lowest IQ of anyone on wikip...   \n",
       "2       Thanks for removing more of his anonymous, un...   \n",
       "3      \"\\n\\nActually, it clearly does not involve pow...   \n",
       "4       You are not cool \\n\\nYou are the most hated f...   \n",
       "...                                                  ...   \n",
       "10103          Heeeeeeeeeeeeeeyyyyyyyyyyyy dude! Sup!      \n",
       "10104  ATTENTION:''''''\\n\\nANYONE WHO OPPOSES MY OPIN...   \n",
       "10105  Oh yah, and Bayerischermann is another guy try...   \n",
       "10106  I had to chop out a section specifically compa...   \n",
       "10107                            Please kill yourself.     \n",
       "\n",
       "                                              more_toxic  certainty  \\\n",
       "0      Re Vandalism. . . .  that is because the user ...   0.666667   \n",
       "1      Wha's a reliable source mike? Something that c...   1.000000   \n",
       "2      To Bad\\nyou dont have the balls to sign in, I ...   1.000000   \n",
       "3      , 18 November 2006 (UTC)\\n\\nWell comrade. Look...   0.666667   \n",
       "4      \"== Hey Fuck-head==\\nHey, just wanted to say \"...   1.000000   \n",
       "...                                                  ...        ...   \n",
       "10103  you deleted my page \\nand i am extrememly mad ...   1.000000   \n",
       "10104          suck dick u disrespectful swearing wank!!   1.000000   \n",
       "10105  Thanks. Also thanks for freezing the article. ...   1.000000   \n",
       "10106  \"\\n\\nHorrifyingly enough, \"\"ritualistic penis ...   0.666667   \n",
       "10107  That's a load of crap. You are letting trolls ...   0.666667   \n",
       "\n",
       "             more_toxic_id        less_toxic_id  \n",
       "0      8871839934638558331 -4761684140996904817  \n",
       "1      1637230891836237423 -7956336680269787100  \n",
       "2     -4417861673610340204 -9111912784081641002  \n",
       "3       538743044374089943  1009349673192730117  \n",
       "4     -8395351920140636842 -8465358288158148543  \n",
       "...                    ...                  ...  \n",
       "10103  -587030008757665900 -6157675788695320718  \n",
       "10104  6392442731289747528 -2454273551981799926  \n",
       "10105  3818525241629339148  7225573479073611155  \n",
       "10106 -2636152035767601275 -3759500075766815347  \n",
       "10107 -8122249264644078195  4348547404275874995  \n",
       "\n",
       "[10108 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score_ccc2017_m1</th>\n",
       "      <th>score_ccc2017_m2</th>\n",
       "      <th>score_ccc2017_m3</th>\n",
       "      <th>score_ccc2017_m4</th>\n",
       "      <th>score_ubtc_m1</th>\n",
       "      <th>score_ruddit_m1</th>\n",
       "      <th>score_ruddit_m2</th>\n",
       "      <th>score_wiki_talk_labels_m1</th>\n",
       "      <th>score_wiki_talk_labels_m2</th>\n",
       "      <th>offenseval_m1</th>\n",
       "      <th>offenseval_m2</th>\n",
       "      <th>c3_m1</th>\n",
       "      <th>c3_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8871839934638558331</td>\n",
       "      <td>Re Vandalism. . . .  that is because the user ...</td>\n",
       "      <td>0.130588</td>\n",
       "      <td>0.240643</td>\n",
       "      <td>0.290199</td>\n",
       "      <td>0.264418</td>\n",
       "      <td>0.280005</td>\n",
       "      <td>0.549056</td>\n",
       "      <td>0.417141</td>\n",
       "      <td>0.315535</td>\n",
       "      <td>0.257190</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.493509</td>\n",
       "      <td>0.346553</td>\n",
       "      <td>0.296056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4761684140996904817</td>\n",
       "      <td>I think people say its not so absurd, because ...</td>\n",
       "      <td>0.085516</td>\n",
       "      <td>0.103158</td>\n",
       "      <td>0.090866</td>\n",
       "      <td>0.187912</td>\n",
       "      <td>0.263704</td>\n",
       "      <td>0.540882</td>\n",
       "      <td>0.606414</td>\n",
       "      <td>0.292525</td>\n",
       "      <td>0.227664</td>\n",
       "      <td>0.529195</td>\n",
       "      <td>0.516643</td>\n",
       "      <td>0.353258</td>\n",
       "      <td>0.299012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1637230891836237423</td>\n",
       "      <td>Wha's a reliable source mike? Something that c...</td>\n",
       "      <td>0.546212</td>\n",
       "      <td>0.623776</td>\n",
       "      <td>0.574130</td>\n",
       "      <td>0.583871</td>\n",
       "      <td>0.871073</td>\n",
       "      <td>0.892588</td>\n",
       "      <td>0.869146</td>\n",
       "      <td>0.895831</td>\n",
       "      <td>0.915215</td>\n",
       "      <td>0.765286</td>\n",
       "      <td>0.786490</td>\n",
       "      <td>0.481011</td>\n",
       "      <td>0.445201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7956336680269787100</td>\n",
       "      <td>You must have the lowest IQ of anyone on wikip...</td>\n",
       "      <td>0.304286</td>\n",
       "      <td>0.387672</td>\n",
       "      <td>0.405968</td>\n",
       "      <td>0.419521</td>\n",
       "      <td>0.802019</td>\n",
       "      <td>0.679649</td>\n",
       "      <td>0.741014</td>\n",
       "      <td>0.765444</td>\n",
       "      <td>0.822827</td>\n",
       "      <td>0.726740</td>\n",
       "      <td>0.722767</td>\n",
       "      <td>0.462803</td>\n",
       "      <td>0.440642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4417861673610340204</td>\n",
       "      <td>To Bad\\nyou dont have the balls to sign in, I ...</td>\n",
       "      <td>0.475488</td>\n",
       "      <td>0.442890</td>\n",
       "      <td>0.586314</td>\n",
       "      <td>0.485561</td>\n",
       "      <td>0.758346</td>\n",
       "      <td>0.780608</td>\n",
       "      <td>0.765925</td>\n",
       "      <td>0.752058</td>\n",
       "      <td>0.718816</td>\n",
       "      <td>0.660960</td>\n",
       "      <td>0.719132</td>\n",
       "      <td>0.472417</td>\n",
       "      <td>0.430983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14246</th>\n",
       "      <td>-3367261662900040048</td>\n",
       "      <td>Guess you never heard of Gaylord Perry, one of...</td>\n",
       "      <td>0.123053</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.100866</td>\n",
       "      <td>0.207610</td>\n",
       "      <td>0.232839</td>\n",
       "      <td>0.500420</td>\n",
       "      <td>0.466802</td>\n",
       "      <td>0.231475</td>\n",
       "      <td>0.199985</td>\n",
       "      <td>0.427846</td>\n",
       "      <td>0.438729</td>\n",
       "      <td>0.326421</td>\n",
       "      <td>0.272859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14247</th>\n",
       "      <td>-587030008757665900</td>\n",
       "      <td>you deleted my page \\nand i am extrememly mad ...</td>\n",
       "      <td>0.135024</td>\n",
       "      <td>0.176959</td>\n",
       "      <td>0.156531</td>\n",
       "      <td>0.180241</td>\n",
       "      <td>0.169857</td>\n",
       "      <td>0.377321</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>0.284193</td>\n",
       "      <td>0.174090</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>0.449750</td>\n",
       "      <td>0.276390</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14248</th>\n",
       "      <td>6392442731289747528</td>\n",
       "      <td>suck dick u disrespectful swearing wank!!</td>\n",
       "      <td>0.595961</td>\n",
       "      <td>0.646268</td>\n",
       "      <td>0.638236</td>\n",
       "      <td>0.659873</td>\n",
       "      <td>0.867191</td>\n",
       "      <td>0.916613</td>\n",
       "      <td>0.880175</td>\n",
       "      <td>0.915201</td>\n",
       "      <td>0.916077</td>\n",
       "      <td>0.941515</td>\n",
       "      <td>0.804194</td>\n",
       "      <td>0.439001</td>\n",
       "      <td>0.393956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14249</th>\n",
       "      <td>-2454273551981799926</td>\n",
       "      <td>ATTENTION:''''''\\n\\nANYONE WHO OPPOSES MY OPIN...</td>\n",
       "      <td>0.135181</td>\n",
       "      <td>0.296563</td>\n",
       "      <td>0.280414</td>\n",
       "      <td>0.361201</td>\n",
       "      <td>0.423764</td>\n",
       "      <td>0.631425</td>\n",
       "      <td>0.516870</td>\n",
       "      <td>0.520577</td>\n",
       "      <td>0.349602</td>\n",
       "      <td>0.456775</td>\n",
       "      <td>0.487076</td>\n",
       "      <td>0.369993</td>\n",
       "      <td>0.312742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14250</th>\n",
       "      <td>-8122249264644078195</td>\n",
       "      <td>That's a load of crap. You are letting trolls ...</td>\n",
       "      <td>0.328013</td>\n",
       "      <td>0.486108</td>\n",
       "      <td>0.503680</td>\n",
       "      <td>0.446717</td>\n",
       "      <td>0.847634</td>\n",
       "      <td>0.728252</td>\n",
       "      <td>0.735746</td>\n",
       "      <td>0.793252</td>\n",
       "      <td>0.754208</td>\n",
       "      <td>0.764397</td>\n",
       "      <td>0.807089</td>\n",
       "      <td>0.492525</td>\n",
       "      <td>0.455983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14251 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                comment_id                                               text  \\\n",
       "0      8871839934638558331  Re Vandalism. . . .  that is because the user ...   \n",
       "1     -4761684140996904817  I think people say its not so absurd, because ...   \n",
       "2      1637230891836237423  Wha's a reliable source mike? Something that c...   \n",
       "3     -7956336680269787100  You must have the lowest IQ of anyone on wikip...   \n",
       "4     -4417861673610340204  To Bad\\nyou dont have the balls to sign in, I ...   \n",
       "...                    ...                                                ...   \n",
       "14246 -3367261662900040048  Guess you never heard of Gaylord Perry, one of...   \n",
       "14247  -587030008757665900  you deleted my page \\nand i am extrememly mad ...   \n",
       "14248  6392442731289747528          suck dick u disrespectful swearing wank!!   \n",
       "14249 -2454273551981799926  ATTENTION:''''''\\n\\nANYONE WHO OPPOSES MY OPIN...   \n",
       "14250 -8122249264644078195  That's a load of crap. You are letting trolls ...   \n",
       "\n",
       "       score_ccc2017_m1  score_ccc2017_m2  score_ccc2017_m3  score_ccc2017_m4  \\\n",
       "0              0.130588          0.240643          0.290199          0.264418   \n",
       "1              0.085516          0.103158          0.090866          0.187912   \n",
       "2              0.546212          0.623776          0.574130          0.583871   \n",
       "3              0.304286          0.387672          0.405968          0.419521   \n",
       "4              0.475488          0.442890          0.586314          0.485561   \n",
       "...                 ...               ...               ...               ...   \n",
       "14246          0.123053          0.143000          0.100866          0.207610   \n",
       "14247          0.135024          0.176959          0.156531          0.180241   \n",
       "14248          0.595961          0.646268          0.638236          0.659873   \n",
       "14249          0.135181          0.296563          0.280414          0.361201   \n",
       "14250          0.328013          0.486108          0.503680          0.446717   \n",
       "\n",
       "       score_ubtc_m1  score_ruddit_m1  score_ruddit_m2  \\\n",
       "0           0.280005         0.549056         0.417141   \n",
       "1           0.263704         0.540882         0.606414   \n",
       "2           0.871073         0.892588         0.869146   \n",
       "3           0.802019         0.679649         0.741014   \n",
       "4           0.758346         0.780608         0.765925   \n",
       "...              ...              ...              ...   \n",
       "14246       0.232839         0.500420         0.466802   \n",
       "14247       0.169857         0.377321         0.353516   \n",
       "14248       0.867191         0.916613         0.880175   \n",
       "14249       0.423764         0.631425         0.516870   \n",
       "14250       0.847634         0.728252         0.735746   \n",
       "\n",
       "       score_wiki_talk_labels_m1  score_wiki_talk_labels_m2  offenseval_m1  \\\n",
       "0                       0.315535                   0.257190       0.571000   \n",
       "1                       0.292525                   0.227664       0.529195   \n",
       "2                       0.895831                   0.915215       0.765286   \n",
       "3                       0.765444                   0.822827       0.726740   \n",
       "4                       0.752058                   0.718816       0.660960   \n",
       "...                          ...                        ...            ...   \n",
       "14246                   0.231475                   0.199985       0.427846   \n",
       "14247                   0.284193                   0.174090       0.412900   \n",
       "14248                   0.915201                   0.916077       0.941515   \n",
       "14249                   0.520577                   0.349602       0.456775   \n",
       "14250                   0.793252                   0.754208       0.764397   \n",
       "\n",
       "       offenseval_m2     c3_m1     c3_m2  \n",
       "0           0.493509  0.346553  0.296056  \n",
       "1           0.516643  0.353258  0.299012  \n",
       "2           0.786490  0.481011  0.445201  \n",
       "3           0.722767  0.462803  0.440642  \n",
       "4           0.719132  0.472417  0.430983  \n",
       "...              ...       ...       ...  \n",
       "14246       0.438729  0.326421  0.272859  \n",
       "14247       0.449750  0.276390  0.235702  \n",
       "14248       0.804194  0.439001  0.393956  \n",
       "14249       0.487076  0.369993  0.312742  \n",
       "14250       0.807089  0.492525  0.455983  \n",
       "\n",
       "[14251 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /home/jovyan/jigsaw-toxic/data/datasets/external_20220207_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.to_csv('/home/jovyan/jigsaw-toxic/data/datasets/external_20220207_stacking/pair.csv', index=False)\n",
    "eval_df.to_csv('/home/jovyan/jigsaw-toxic/data/datasets/external_20220207_stacking/feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions_by_mean(\n",
    "        valid_df: pd.DataFrame,\n",
    "        eval_df: pd.DataFrame,\n",
    "        score_arr_list: t.List[np.ndarray],\n",
    "        apply_rankdata: bool = False) -> t.Tuple[np.ndarray, np.ndarray]:\n",
    "    if apply_rankdata:\n",
    "        score_arr_list = [rankdata(score_arr, method='ordinal') for score_arr in score_arr_list]\n",
    "    score_arr = np.stack(score_arr_list, axis=0).mean(axis=0)\n",
    "    comment_id_to_score_dict = dict(zip(eval_df['comment_id'].tolist(), score_arr.flatten().tolist()))\n",
    "    more_toxic_score_list, less_toxic_score_list = [], []\n",
    "    for _, row in valid_df.iterrows():\n",
    "        more_toxic_score_list.append(comment_id_to_score_dict[int(row['more_toxic_id'])])\n",
    "        less_toxic_score_list.append(comment_id_to_score_dict[int(row['less_toxic_id'])])\n",
    "    return np.array(more_toxic_score_list), np.array(less_toxic_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable: t.Iterable[str]) -> t.Iterable[t.Tuple[str, ...]]:\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Score dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = dict([\n",
    "    ('ccc2017_m1_score_arr', ccc2017_m1_score_arr),\n",
    "    # ('ccc2017_m2_score_arr', ccc2017_m2_score_arr),\n",
    "    ('ccc2017_m3_score_arr', ccc2017_m3_score_arr),\n",
    "    # ('ccc2017_m4_score_arr', ccc2017_m4_score_arr),\n",
    "    # ('ubtc_m1_score_arr', ubtc_m1_score_arr),\n",
    "    # ('ubtc_m2_score_arr', ubtc_m2_score_arr),\n",
    "    ('ruddit_m1_score_arr', ruddit_m1_score_arr),\n",
    "    ('ruddit_m2_score_arr', ruddit_m2_score_arr),\n",
    "    ('wiki_talk_labels_m1_score_arr', wiki_talk_labels_m1_score_arr),\n",
    "    # ('wiki_talk_labels_m2_score_arr', wiki_talk_labels_m2_score_arr),\n",
    "    # ('offenseval_m1', offenseval_m1_score_arr),\n",
    "    # ('offenseval_m2', offenseval_m2_score_arr),\n",
    "    # ('c3_m1', c3_m1_score_arr),\n",
    "    # ('c3_m2', c3_m2_score_arr),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_toxic_score_arr, less_toxic_score_arr = ensemble_predictions_by_mean(\n",
    "    valid_df=valid_df,\n",
    "    eval_df=eval_df,\n",
    "    score_arr_list=[\n",
    "        ccc2017_m1_score_arr,\n",
    "        ccc2017_m3_score_arr,\n",
    "        ruddit_m1_score_arr,\n",
    "        ruddit_m2_score_arr,\n",
    "        wiki_talk_labels_m1_score_arr,\n",
    "    ],\n",
    "    apply_rankdata=True)\n",
    "(more_toxic_score_arr > less_toxic_score_arr).astype(np.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_ensemble_result_dict: t.Dict[str, float] = {}\n",
    "# _it = tqdm(sorted([sub for sub in powerset(score_dict.keys()) if len(sub) >= 4], key=len, reverse=True))\n",
    "# for score_key_set in _it:\n",
    "#     if not score_key_set:\n",
    "#         continue\n",
    "#     more_toxic_score_arr, less_toxic_score_arr = ensemble_predictions_by_mean(\n",
    "#         valid_df=valid_df,\n",
    "#         eval_df=eval_df,\n",
    "#         score_arr_list=[score_dict[score_key] for score_key in list(score_key_set)],\n",
    "#         apply_rankdata=True,\n",
    "#     )\n",
    "#     key = ' '.join(sorted(score_key_set))\n",
    "#     score = (more_toxic_score_arr > less_toxic_score_arr).astype(np.float32).mean()\n",
    "#     mean_ensemble_result_dict[key] = score\n",
    "#     best_key, best_score = max(mean_ensemble_result_dict.items(), key=lambda x: x[1])\n",
    "#     _it.set_description(f'Best score: {best_score:.5f}, best key: {best_key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score: 0.76059\n",
    "Best models:\n",
    " - ccc2017_m1_score_arr\n",
    " - ccc2017_m3_score_arr \n",
    " - ruddit_m1_score_arr\n",
    " - ruddit_m2_score_arr\n",
    " - wiki_talk_labels_m1_score_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_ensemble_result_dict: t.Dict[str, float] = {}\n",
    "# _it = tqdm(sorted([sub for sub in powerset(score_dict.keys()) if len(sub) >= 4], key=len, reverse=True))\n",
    "# for score_key_set in _it:\n",
    "#     if not score_key_set:\n",
    "#         continue\n",
    "#     more_toxic_score_arr, less_toxic_score_arr = ensemble_predictions_by_sort(\n",
    "#         valid_df=valid_df,\n",
    "#         eval_df=eval_df,\n",
    "#         score_arr_list=[score_dict[score_key] for score_key in list(score_key_set)],\n",
    "#         distribution=PowerDistribution(min=0.0, max=1.0, power=1.0),\n",
    "#         apply_rankdata=False)\n",
    "#     key = ' '.join(sorted(score_key_set))\n",
    "#     score = (more_toxic_score_arr > less_toxic_score_arr).astype(np.float32).mean()\n",
    "#     sort_ensemble_result_dict[key] = score\n",
    "#     best_key, best_score = max(sort_ensemble_result_dict.items(), key=lambda x: x[1])\n",
    "#     _it.set_description(f'Best score: {best_score:.5f}, best key: {best_key}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
